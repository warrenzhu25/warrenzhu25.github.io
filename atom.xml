<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Warren's Blog]]></title>
  <link href="http://warrenzhu25.github.io/atom.xml" rel="self"/>
  <link href="http://warrenzhu25.github.io/"/>
  <updated>2018-02-18T17:44:49+08:00</updated>
  <id>http://warrenzhu25.github.io/</id>
  <author>
    <name><![CDATA[Warren Zhu]]></name>
    <email><![CDATA[warren.zhu25@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Redis Learning Notes]]></title>
    <link href="http://warrenzhu25.github.io/blog/redis-learning-notes/"/>
    <updated>2017-11-18T16:45:27+08:00</updated>
    <id>http://warrenzhu25.github.io/blog/redis-learning-notes</id>
    <content type="html"><![CDATA[<h2>Cluster</h2>

<h3>Redis cluster 101</h3>

<ul>
<li>automatically split your dataset among multiple nodes.</li>
<li>continue operations when a subset of the nodes are experiencing failures</li>
</ul>


<h3>Data sharding</h3>

<ul>
<li>16384 total hash slots</li>
<li>hash slot = CRC16(key) % 16384</li>
<li>Every node is responsible subset of hash slots. Need manually assign.</li>
<li>Use <strong>hash tag</strong> to keys to be the same hash slot. For example, <strong>this{foo}key</strong> and <strong>another{foo}key</strong></li>
</ul>


<h3>Master slave model</h3>

<p>Slave will be promoted to the master if one master is down to keep cluster running.</p>

<h3>Consistency guarantee</h3>

<ul>
<li><strong>No strong consistency</strong>. Cluster may lose writes acknowledged.</li>
<li>Due to asynchronous replication, the slave which behind master might be promoted to be new master</li>
</ul>


<h3>How to config</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>port 7000
</span><span class='line'>cluster-enabled yes
</span><span class='line'>cluster-config-file nodes.conf
</span><span class='line'>cluster-node-timeout 5000
</span><span class='line'>appendonly yes</span></code></pre></td></tr></table></div></figure>


<h3>Design goals</h3>

<ol>
<li>High performance and linear scalability up to 1000 nodes</li>
<li>Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the master nodes.</li>
<li>Availability: Redis Cluster is able to survive partitions where the majority of the master nodes are reachable and there is at least one reachable slave for every master node that is no longer reachable.</li>
</ol>


<h3>Eviction</h3>

<h3>Eviction policies</h3>

<ul>
<li><strong>noeviction</strong>: return errors when the memory limit was reached and the client is trying to execute commands that could result in more memory to be used (most write commands, but DEL and a few more exceptions).</li>
<li><strong>allkeys-lru</strong>: evict keys by trying to remove the less recently used (LRU) keys first, in order to make space for the new data added.</li>
<li><strong>volatile-lru</strong>: evict keys by trying to remove the less recently used (LRU) keys first, but only among keys that have an expire set, in order to make space for the new data added.</li>
<li><strong>allkeys-random</strong>: evict keys randomly in order to make space for the new data added.</li>
<li><strong>volatile-random</strong>: evict keys randomly in order to make space for the new data added, but only evict keys with an expire set.</li>
<li><strong>volatile-ttl</strong>: evict keys with an expire set, and try to evict keys with a shorter time to live (TTL) first, in order to make space for the new data added.</li>
</ul>


<h3>Approximated LRU algorithm</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>maxmemory-samples 5</span></code></pre></td></tr></table></div></figure>


<h2>Metrics</h2>

<h3>Memory</h3>

<ul>
<li><strong>used_memory</strong>: total number of bytes allocated by Redis using its allocator (either standard libc, jemalloc, or an alternative allocator such as tcmalloc</li>
<li><strong>used_memory_human</strong>: Human readable representation of previous value</li>
<li><strong>used_memory_rss</strong>: Number of bytes that Redis allocated as seen by the operating system (a.k.a resident set size). This is the number reported by tools such as top(1) and ps(1).

<ul>
<li>rss >> used means fragmentation.</li>
<li>used >> rss means part of memory swapped, expect significant latency</li>
<li>Redis will not always free up (return) memory to the OS when keys are removed. So <strong>maxmemory</strong> should be based on peak memory usage. However allocators are abke to reuse free memory. Because of all this, fragmentation ratio is not reliable when peak memory >>> currently used memory.</li>
</ul>
</li>
<li><strong>used_memory_peak</strong>: Peak memory consumed by Redis (in bytes)</li>
<li><strong>used_memory_peak_human</strong>: Human readable representation of previous value</li>
<li><strong>used_memory_lua</strong>: Number of bytes used by the Lua engine</li>
<li><strong>mem_fragmentation_ratio</strong>: Ratio between used_memory_rss and used_memory</li>
<li><strong>mem_allocator</strong>: Memory allocator, chosen at compile time</li>
</ul>


<h2>Persistency</h2>

<h3>RDB: point-in-time snapshots of dataset at specified interval</h3>

<h4>Pros</h4>

<p>compact, good for disaster recovery, little performance overhead, faster restarts</p>

<h4>Cons</h4>

<p>certain data loss, fork() often. (AOF can tune rewrite fork frequency)</p>

<h3>AOF: logs every write operation, that will be played again at server startup</h3>

<h4>Pros</h4>

<ul>
<li>more durable, control fsync policy</li>
<li>append-only file, no seek, no corruption, could be fixed</li>
<li>rewrite big AOF in background</li>
</ul>


<h4>Cons</h4>

<p>bigger than RDB, slower, less robust</p>

<h4>What should I use</h4>

<ul>
<li>Use both if you want data safety like PostgreSQL</li>
<li>Use RBD alone if you live with minutes of data loss</li>
<li>Discourage to use AOF alone</li>
</ul>


<h4>How config RDB</h4>

<p>Dump every 60 seconds if at least 1000 keys changed</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>save 60 1000 </span></code></pre></td></tr></table></div></figure>


<h4>How RDB works</h4>

<ol>
<li>Redis forks. We now have a child and a parent process.</li>
<li>The child starts to write the dataset to a temporary RDB file.</li>
<li>When the child is done writing the new RDB file, it replaces the old one.</li>
</ol>


<h4>How enable AOF</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>appendonly yes</span></code></pre></td></tr></table></div></figure>


<h4>How AOF log rewritting works</h4>

<ol>
<li>Redis forks, so now we have a child and a parent process.</li>
<li>The child starts writing the new AOF in a temporary file.</li>
<li>The parent accumulates all the new changes in an in-memory buffer (but at the same time it writes the new changes in the old append-only file, so if the rewriting fails, we are safe).</li>
<li>When the child is done rewriting the file, the parent gets a signal, and appends the in-memory buffer at the end of the file generated by the child.</li>
<li>Profit! Now Redis atomically renames the old file into the new one, and starts appending new data into the new file.</li>
</ol>


<h4>How durable is the append only file?</h4>

<ol>
<li>fsync every time new command appended. Very very slow, very saft</li>
<li>fsync every second. Fast enough.</li>
<li>Never fsync, rely on OS. faster and less safer.</li>
</ol>


<h2>Replication</h2>

<h3>Three main mechanism:</h3>

<ol>
<li>When master and slave are well-connected, master send a stream of commands.</li>
<li>When link breaks, slave reconnects and proceeds with partial resynchronization: obtain part of stream of commands</li>
<li>When partial resynchronization is impossible, slave ask for full resynchronization. Master send snapshot to slave, then send stream of commands.</li>
</ol>


<h3>Important facts</h3>

<ul>
<li>Asynchronous replication</li>
<li>Replication is non-blocking on the master side.</li>
<li>A master can have multiple slaves.</li>
<li>Slave are able to accept connections from other slaves.</li>
</ul>


<h3>Allow writes only with N attached replicas</h3>

<ul>
<li>slaves ping the master every second, acknowledging the amount of replication stream processed.</li>
<li>masters will remember the last time it received a ping from every slave.</li>
<li>The user can configure a minimum number of slaves that have a lag not greater than a maximum number of seconds.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>min-slaves-to-write &lt;number of slaves&gt;
</span><span class='line'>min-slaves-max-lag &lt;number of seconds&gt;</span></code></pre></td></tr></table></div></figure>


<h3>How deal with expiration</h3>

<ol>
<li>Slave don&rsquo;t expire keys, master send <strong>DEL</strong> after key expire</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git FAQ]]></title>
    <link href="http://warrenzhu25.github.io/blog/git-faq/"/>
    <updated>2017-11-18T16:45:27+08:00</updated>
    <id>http://warrenzhu25.github.io/blog/git-faq</id>
    <content type="html"><![CDATA[<h2>How to revert staged changes</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git reset
</span><span class='line'>git reset fileName
</span></code></pre></td></tr></table></div></figure>


<h2>How to diff staged and tracked changes</h2>

<h3>Show what has been added to the index via git add but not yet committed.</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git diff --staged</span></code></pre></td></tr></table></div></figure>


<h3>Shows what has changed since the last commit.</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git diff HEAD</span></code></pre></td></tr></table></div></figure>


<h3>Show what has changed but hasn&rsquo;t been added to the index yet via git add.</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git diff</span></code></pre></td></tr></table></div></figure>


<h3>Shows what has changed since the commit before the latest commit</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git diff HEAD^</span></code></pre></td></tr></table></div></figure>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[三读java编程思想]]></title>
    <link href="http://warrenzhu25.github.io/blog/%E4%B8%89%E8%AF%BBJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/"/>
    <updated>2014-11-06T00:00:00+08:00</updated>
    <id>http://warrenzhu25.github.io/blog/三读Java编程思想</id>
    <content type="html"><![CDATA[<p>﻿&mdash;
title: &ldquo;三读Java编程思想&rdquo;</p>

<h2>categories: Reading </h2>

<p>又一次，或者准确地说，第三次读完了《Java编程思想》，合上书，我陷入沉思之中，这本书为什么值得我一而再，再而三地去读它呢？而且，似乎每遍重读，似乎总有些新的收获。我尽我所能来阐述其原因，希望在本文结束之时，我们共同拥有一个满意的答案。</p>

<h2>为什么此书值得读？</h2>

<p>为什么是这本书，而不是其他书呢？先卖个关子，中学的时候有一个奇怪的现象，有的老师，再听他讲课的时候，没觉得难，但是，听完之后，却发现已经把一个很难的问题在不知不觉之中搞明白了。现在想想，这其实就是大师的能力，他可以化繁为简，把复杂的问题用简单的语言解释清楚。而此书的作者Bruce Eckel就是当之无愧的大师，他拥有丰富的Java教学经验，又对Java有独到的见解，而且对Java的很多设计提出了问题和建议。此书独特的地方可以归结为以下几个方面：</p>

<ol>
<li><p><strong>每次一小步。</strong>每次只介绍一个知识点，在确保读者能够掌握之后，再介绍新的知识点。如此，读者理解起来更加容易，也更有成就感，同时也不会因为众多纠缠不清的知识点而迷惑，这就是此书中文版厚达880页的原因。</p></li>
<li><p><strong>每个知识点都有对应的可编译执行的代码例子。</strong>读者可以自己运行，加深理解。当有疑问时，也可以通过修改代码，自我验证，在不知不觉中得到提高。</p></li>
<li><p><strong>采用测试框架展示程序输出。</strong>有以下优点:</p>

<ul>
<li>培养读者对测试的重视，在实际工作中，很多初学者容易忽视测试的重要性。</li>
<li>培养读者去写出可测试的代码，比如紧密耦合等，都会导致程序很难测试。</li>
<li>培养读者如何写测试框架，这对工作中写单元测试和其他测试都很有帮助。</li>
<li>要修改程序时，比如重构，可以通过测试框架来确保程序的正确性。</li>
</ul>
</li>
<li><p><strong>示例中运用众多设计模式。</strong>关于设计模式的重要性，相信大家都知道，只是面向对象设计的基本功，结合实际的例子来学习，可以说是一举两得。有些功能，有很深入的探讨。比如泛型，通过与C++的对比，介绍了设计思路和优缺点。</p></li>
</ol>


<h2>为什么值得读3遍？</h2>

<p>先介绍以下我读此书的经历：</p>

<ol>
<li>2010年初，购入此书第四版中文版。此前，在Stackoverflow，见多人推荐此书。
半年时间，读第一遍，当然很多问题浅尝辄止，没有搞明白，总算是翻完了以便。最大的感受是，原来Java还有这么多我不知道的功能。</li>
<li>2011年，工作之后，发现真正写代码的时候，很多都是一知半解。比如，容器和泛型应该怎么用，并发该怎么写，异常该如何处理，IO的框架是怎么回事。不过，总算知道这些东西的存在。又花了半年的时间，第二遍。这次，带着问题有目的性地把相应的章节仔细地重读了一遍。工作中的问题得到顺利解决了，但是好奇心没有得到充分的满足，很多东西不知道为什么要这么用。</li>
<li>2012年初，购入此书第四版英文版。因为我认为翻译不可能没有信息损失，这些损失很可能使我不能正确理解作者要表达的意思。开始阅读第三遍，花了1年左右。这次可是说是咬文嚼字，很多不认识的单词还查了词典。读完第一章对象导论，我就大有收获。之前竟然没有发现这章如此之好，从哲学的对象到编程中的对象，对面向对象做了全面而准确的解释，读完之后，豁然开朗。之后，更是惊喜不断，尤其是异常那一章，对检查型异常的优缺点做了详细的论述，并提出了解决方案来克服检查型异常的缺点，让了理解了为什么这个功能只在Java中存在（在Python， C#中都没有检查型异常）

<h2>学习的过程</h2>

<p>在Java Performance的开头，作者认为，要想成功地调优Java性能，你需要经历三个阶段：</p></li>
</ol>


<p>我不知道我要知道什么。也就是说，在解决一个问题是，你不知道你需要知道什么知识和方法才能解决问题。
我知道我要知道什么。你知道你要了解哪些重要的东西才能解决问题，但是你还没有研究过那些重要内容的细节。
我已经知道了我需要知道的。简而言之，你了解并理解了所有的细节。
我认为，还要加上一个阶段:</p>

<p>我质疑并改进我已经知道的。对于我所掌握的知识和细节，我会持怀疑的态度问自己，为什么要怎么做才能解决问题？怎么做有什么优缺点？有没有其他的方法，更好的方法？
你会发现，我读《Java编程思想》的经历完整得重现这四个阶段：</p>

<ol>
<li><strong>未读之前</strong>，我不知道要知道什么才能用好Java。</li>
<li><strong>一遍之后</strong>，我知道我要理解面向对象，异常，并发，泛型，IO等才能用好Java。</li>
<li><strong>两遍之后</strong>，我理解了所有的技术细节。</li>
<li><strong>三遍时，</strong>我开始评价并反思所有的技术细节，以及它们从何而来，为什么成为现在这样，以后又会去向何方。

<h2>结论</h2>

<p>相信读者读到这里，应该已经能够理解我为什么读三遍《Java编程思想》。如果您读完此文，决定读一下《Java编程思想》；如果您读完此文，决定好书以后要读三遍，我知足矣。</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
